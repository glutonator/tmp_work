\newpage % Rozdziały zaczynamy od nowej strony.
\section{Eksperymenty}

\colorbox{yellow}{todo: opisać to jakoś sensownie, punkt po punkcie co i dlaczego robię, bo teraz jest tak mega chatycznie, że nie da sie nic wywniskować}\\

//dlaczego takie sieci został ywybran, dlaczeg otakimi paramterami steruję -> na co powinny one wpływać

%W ramach pracy została dokonana analiza wpływu oznaczeń morfosyntaktycznych na jakość klasyfikacji tekstów ironicznych. Na potrzeby języka angielskiego taka analiza sprowadza się głownie do analizy wpływu typu części mowy do jakiego należą poszczególne słowa i taka analiza zostanie podjęta w kolejnych krokach.

% \colorbox{yellow}{highlight}\\

Na potrzeby analizy wykorzystano wiele różnych modeli sieci neuronowych, bazujących głownie na trzech typach warstw:

\begin{itemize}
    \item gęstej;
    \item konwolucyjnej;
    \item LSTM;
\end{itemize}

W ramach różnych architektur testowany był wpływ kilku hiperparametrów na jakość klasyfikacji. Oto lista niektórych z nich:
\begin{itemize}
    \item dla warstwy gęstej:
          \begin{itemize}
              \item  1/2/3 warstwy
              \item Z dropoutem / bez dropoutu
              \item Wielkość wartwy ukrytej 30-200
          \end{itemize}

    \item dla warstwy konwolucyjnej;
          \begin{itemize}
              \item  1/2/3 warstwy
              \item Wielkość okna 3-15
              \item Z dropoutem / bez dropoutu
              \item Wielkość wartwy ukrytej 30-200
          \end{itemize}
    \item dla warstwy LSTM;
          \begin{itemize}
              \item Wykorzystanie warstwy pojedynczej (LSTM) oraz podwójnej (Bi-LSTM)
              \item  1/2/3 warstwy
              \item Z dropoutem / bez dropoutu
              \item Wielkość wartwy ukrytej 30-200
          \end{itemize}
\end{itemize}

% \subsection{POSTAGS}
% %todo:
% //todo: zmergować z dugim rozdiałem o postagach

% Aby możliwe było wykorzystanie przez sieć neuronową informacji na temat typu części mowy danego słowa konieczne są następujące kroki:

% \begin{enumerate}
%     \item Rozpoznanie części mowy w kontekście zdania i przypisanie do niego odpowiedniego tagu,
%     \item Konwersja wykrytego tagu do liczbowej reprezentacji wektorowej,
%     \item Dołączenie utworzonego wektora do przetrenowanego wektora embedingów.
% \end{enumerate}

% \hfill \break % to dodaje pustą linie po czymść dziwnym -lista, tabela
% Do rozpoznania części mowy zostało wykorzystane narzędzie z pakietu NLTK, które pozwala na oznaczenie każdego słowa w zdaniu jednym z 46 tagów, każdy odpowiadający innej części mowy. Następnie wykryty tag został przetworzony do postaci “one-hot encoding” i dodany do istniejącego embedingu słowa, zwiększając tym samy jego rozmiar o długość 46.


\subsection{Wyniki analiza}

\subsubsection{Eksperyment 1}
% Aby w pełni zweryfikować wpływ części mowy (POS tagów) na jakość klasyfikacji zostały wykorzystane trzy różne embeddingi oraz dwa różne zbiory danych wejściowych. Embeddingi różnią się one między innymi długością oraz metodą ich uzyskiwania. A zbiory danych różnią się licznością i stopniem zaszumienia. Każdy ze zbiorów danych został podzielony na trzy zbiory treningowy, walidacyjny oraz testowy w proporcjach 60/20/20 procent.

Aby w pełni zweryfikować wpływ części mowy (POS tagów) na jakość klasyfikacji zostały wykorzystane trzy różne embeddingi oraz dwa różne zbiory danych wejściowych. Wykorzsytane embeddingi to: Glove, FastText oraz ELMo, a ich dokładniejszy opis znajduje się w rozdziale \ref{embeddings}. Natomiast dwa zbiory danych wejściowych (oznaczonych jako A oraz B) są opisane w rozdziale \ref{dane_wejsciowe}. Na potrzeby budowania modeli każdy ze zbiorów danych został podzielony na trzy podzbiory: treningowy, walidacyjny oraz testowy w proporcjach 60/20/20 procent.

% Poniżej przedstawiono tabele z wynikami obliczeń.
Wyniki uzyskane przez modele na danych testowych zbioru A zostały umiszczone w rozdziale \ref{wyniki_eksperymentow} w tabelach \ref{tab:wyniki_glove_A}, \ref{tab:wyniki_fasttext_A}, \ref{tab:wyniki_elmo_A} , a dla zbioru B w tabelach \ref{tab:wyniki_glove_B}, \ref{tab:wyniki_fasttext_B}, \ref{tab:wyniki_elmo_B}.


W oparciu o uzyskane wyniki można stwierdzić, że wraz z dołączeniem informacji o częściach mowy nie obserwuje się widocznej poprawy jakości klasyfikacji, czasem występuje nawet jej pogorszenie. Jednym z powodów takiego zachowania może być fakt, że rodzaj części mowy nie jest kluczowy do rozpoznania ironicznego charakteru tekstu. Możne to być też spowodowane tym, że sieci wychwytują niezbędne dla nich informacje na temat roli konkretnego słowa w zdaniu w oparciu o uzyskiwany kontekst i dodatkowa informacja w ramach embeddingu jest już niepotrzebna.

Ponadto można zaważyć, że wraz ze wzrostem rozmiaru embedingów poprawia się jakość klasyfikacji, co jest zgodne z oczekiwaniami, jako że dłuższy embedding pozwala na zachowanie większej liczby informacji na temat słowa.


Analizując uśrednione pomiary jakości klasyfikacji dla sieci opartych o różne typy warstw, można zauważyć, że najgorzej sprawują się sieci oparte o warstwy gęste. Natomiast sieci wykorzystujące warstwy konwolucyjne oraz LSTM posiadają podobną skuteczność klasyfikacji. Aby wykluczyć wpływ zaszumienia danych oraz przeuczenia sieci wykonano jeszcze dwa eksperymenty mające porównać skuteczność klasyfikacji sieci opartych na warstwach konwolucyjnych oraz LSTM. Eksperymenty te są przeprowadzone na danych wejściowych pozbawionych informacji o częściach mowy, gdyż z dotychczasowych pomiarów wynika, iż mają one pomijalny wpływ na jakość klasyfikacji.

%\colorbox{yellow}{todo: todo opisanie, że zbior duży to zbiór B, a mały zbiór to zbiór A}\\
%todo opisanie, że zbior duży to zbiór B, a mały zbiór to zbiór A

\subsubsection{Eksperyment 2 - Uczenie modelu na zbiorze B i testowanie jakoś klasyfikacji na zbiorze A }

W ramach tego eksperymentu zbiór danych oznaczonych jako \textbf{B} został podzielony na dwa zbiory: treningowy oraz w walidacyjny w proporcjach 80/20 procent. Natomiast zbiór oznaczony jako A został w całości wykorzystany jako zbiór testowy. Wyniki zawierają tabele poniżej.

%todo:
\colorbox{yellow}{todo:}\\
% //tabela dla różnych embedingów pokazująca, że sieci oparte o warstwy konwolucyjne mają najlepszą zdolnośc do generalizacji
//tablea gdzie jest jakość na poziomie 50-55 procent

%todo:
\colorbox{yellow}{todo:}\\
% //Wymyślić wnioski dla teakiej sytuacji
W oparciu o uzyskane miary jakość klasyfikacji można stwierdzić, że modele wyuczone na zbiorze B źle radzą sobie z klasyfikacją rekordów ze zbioru A. Dokładność na poziomie pięćdziesięciu paru procent wskazuje, że pomimo tego, że oba zbiory pochodzą z tego samego źródła to różnią się one na tyle bardzo swoją strukturą wewnętrzną, że żadna architektura nie może sobie poradzić z prawidłową klasyfikacją. Co potwierdza powszechnie znaną prawdę dotyczącą sieci neuronowych, że takie modele do procesu trenowania potrzebują bardzo dużej ilości danych o możliwie jak najbardziej zróżnicowanej strukturze. Wystarczy, że zbiór danych treningowych jest tylko pewnym wycinkiem dziedziny problemu, który sieć ma rozwiązać, by nauczyła się ona klasyfikacji złych cech.


\subsubsection{Eksperyment 3 - Uczenie i testowanie modelu na fragmencie zbioru dużego B tak by był równoliczny ze zbiorem małym A}

W ramach tego eksperymentu ze zbioru danych oznaczonych jako \textbf{B} zostało wybranych w losowy sposób 2000 rekordów ironicznych i tyle samo nieironicznych, tak by licznością były porównywalne ze zbiorem oznaczonym jako \textbf{A}. Tak uzyskany zbiór został podzielony na trzy podzbiory: treningowy, walidacyjny oraz testowy w proporcjach 60/20/20 procent. Wyniki zawierają tabele poniżej.

%todo:
\colorbox{yellow}{todo:}\\
//tabela dla roznych embedingow pokazujaca, że wartwa konwolucyjna jest o 5 procent gorsze od LSTM


W oparciu o uzyskane wyniki można zauważyć:

\begin{itemize}
    \item Wyższą średnią jakoś klasyfikacji w porównaniu do zbioru oznaczonego jako \textbf{A}
    \item Lepszą jakość klasyfikacji dla sieci opartych o warstwy typu LSTM
\end{itemize}


Wyższa jakoś klasyfikacji może wskazywać na to, że zbiór oznaczony jako \textbf{A} posiada dużo bardziej zróżnicowane dane, przy czym zbiór posiada zbyt małą liczbą próbek by sieć, w procesie nauki, odpowiednio je wychwyciła. Problem ten może być najprawdopodobniej wyeliminowany poprzez dostarczenie większej liczby próbek danych o zróżnicowanym charakterze.

Lepsza jakość klasyfikacji przez sieci oparte o warstwy LSTM jest zgodny z wnioskami płynącymi z innych publikacji badających podobne zagadnienia. Trudności z obserwacji tej zależności w poprzednich eksperymentach mogła wynikać między innymi z:


\begin{itemize}

    \item Dla zbioru A:
          \begin{itemize}
              \item Małej liczby próbek
              \item Dużej różnorodności prezentowanej ironii w próbkach
          \end{itemize}

    \item Dla zbioru B:
          \begin{itemize}
              \item Małej różnorodności prezentowanej ironii w próbkach
              \item Na tyle duża liczba próbek, by sieci o teoretycznie gorszych zdolnościach do rozwiązywania danego zadania klasyfikacji mogły wychwycić cechy tekstu pozwalające, przy odpowiednio długim procesie uczenia, na poprawną klasyfikację.
          \end{itemize}

\end{itemize}



\begin{table}[h] \centering
    \caption{Embedding Glove o długości 25, zbiór A}
    \label{tab:wyniki_glove_A}
    \begin{tabular} {|c|c|c|c|c|c|c|c|c| }    \hline
    & \multicolumn{8}{c|}{metryki}                                                                                                                               \\ \hline
    X        & \multicolumn{2}{c|}{accuracy} & \multicolumn{2}{c|}{precision} & \multicolumn{2}{c|}{recall} & \multicolumn{2}{c|}{f1}                                     \\ \hline
    sieć     & N                             & P                              & N                           & P                       & N      & P      & N      & P      \\ \hline
    dense\_1  & 0.6327 & \textbf{0.6372} & 0.6074 & \textbf{0.6210} & \textbf{0.6853} & 0.6456 & \textbf{0.6440} & 0.6331 \\ \hline
    dense\_2  & \textbf{0.6022} & 0.5943 & 0.5790 & \textbf{0.5732} & \textbf{0.6573} & 0.6386 & \textbf{0.6157} & 0.6041 \\ \hline
    cnn\_11   & \textbf{0.6395} & 0.6327 & 0.6227 & \textbf{0.6111} & \textbf{0.6503} & 0.6666 & \textbf{0.6362} & 0.6376 \\ \hline
    \end{tabular}
    \end{table}
    




