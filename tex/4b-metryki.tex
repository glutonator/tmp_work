% \newpage % Rozdziały zaczynamy od nowej strony.
% \section{Proces uczenia}



\subsection{Funkcja straty}

Proces uczenia sieci neuronowej wykorzystuje mechanizm wstecznej propagacji błędu, który pozwala na regulacje wag połączeń między neuronami tak by poprawiać uzyskiwane wyniki wartwy wyjściowej wraz z każdą kolejną iteracją. W ramach tego mechanizmu konieczne jest wyznaczenie uzyskiwanego przez sieć błędu zgodnie z pewna stałą metryką. W przypadku zagadnienia klasyfikacji binarnej, najpopularniejszą funkcją jest funkcja binarnej entropii krzyżowej (ang. binary cross entropy), i będzie ona także wykorzystywana w ramach tej pracy. Opisuje się ona poniższym wzorem: 

$$
CE = -\sum_{i=1}^{C'=2}t_{i} log (f(s_{i})) = -t_{1} log(f(s_{1})) - (1 - t_{1}) log(1 - f(s_{1})),
$$


\noindent gdzie: \\
$s_1$ - uzyskany stan dla klasy pierwszej \\
$t_1$ - oczekiwany stan dla klasy pierwszej (wartość 0)\\
$1-s_1$ - uzyskany stan dla klasy drugiej \\
$1-t_1$ - oczekiwany stan dla klasy drugiej (wartość 1) \\
$f(s_i)=\frac{1}{1+e^{-s_i}}$ - funkcja sigmoidalna



\subsection{Wykorzystane metryki}

Jakość klasyfikacji można monitorować przy wykorzystaniu różnych metryk. Najbardziej popularną metryką jest dokładność (ang. accuraccy), czyli stosunek poprawnie zakwalifikowanych przez model obserwacji, do całkowitej liczby obserwacji w zbiorze. Nie jest to jednak miara idealna, nie bierze ona pod uwagę między innymi tego czy badany zbiór jest zbilansowany. W przypadku zbioru niezbilansowanego możliwe jest uzyskanie bardzo dobrej dokładności nawet przy zakwalifikowaniu wszystkich obserwacji do tylko jednej klasy. W celu wyeliminowania tego problemu wykorzystuje się inne metryki, takie jak precyzja i czułość \cite{metryki_3}.



\noindent Powyższe metryki wykorzystują następujące pojęcia pomocnicze:
\begin{itemize}
    \item true positive (TP) - liczba pozytywnych obserwacji zaklasyfikowanych jako pozytywne
    \item true negative (TN) - liczba negatywnych obserwacji zaklasyfikowanych jako negatywne
    \item false positive (FP) - liczba negatywnych obserwacji zaklasyfikowanych jako pozytywne
    \item false negative (FN) - liczba pozytywnych obserwacji zaklasyfikowanych jako negatywne
\end{itemize}


\noindent W oparciu o te pojęcia pomocnicze można sformułować następujące zależności:

% $$
%     dokładność = \frac{\ liczba\ poprawnie\ zakwalifikowanych\ obserwacji\ }{\ całkowita\ liczba\ obserwacji\ }
% $$

$$
    precyzja = \frac{TP}{TP + FP}
$$

$$
    czułość = \frac{TP}{TP + FN}
$$


%https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall 

%https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/ 

%https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9 

W oparciu o wzory można zauważyć, że precyzja zawiera w sobie informację jaka część obserwacji zakwalifikowanych jako pozytywne była zakwalifikowana poprawnie. Natomiast czułość zawiera informację na temat tego jaka część pozytywnych obserwacji została zakwalifikowana poprawnie \cite{metryki_1}.

Precyzja i czułość są ze sobą współzależne, w przypadku, gdy wskazania jednej z metryk się poprawiają, to wskazania drugiej metryki spadają. Aby monitować optymalne wskazania obu metryk powstała metryka F1, jest ona opisana poniższym wzorem \cite{metryki_2}:

$$
    F1 = 2 \cdot \frac{precyzja \cdot czułość}{precyzja + czułość}
$$

Podczas procesu analizy uzyskanych przez sieć wartości poszczególnych metryk, brane były pod uwagę przede wszystkim dwie z nich: dokładność oraz F1. Dokładność pozwalała na interpretację czy sieć zachowywała się lepiej niż model naiwny przypisujący wszystkim elementom zbioru testowego tą samą, jedna klasę (zbiór jest zbiorem zbilansowanym, o dwóch równolicznych klasach). Jeśli dokładność była na odpowiednio wysokim poziomie analizie podlegała metryka F1, co pozwalało na uwzględnienie wpływu “false positive” oraz “false negative” na jakość klasyfikacji modelu. 





